{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các đặc tính: ['city=Chicago' 'city=Los Angeles' 'city=New York' 'city=San Francisco'\n",
      " 'humidity' 'temperature']\n",
      "Dữ liệu sau khi biến đổi:\n",
      " [[ 0.  0.  1.  0. 68. 21.]\n",
      " [ 0.  1.  0.  0. 75. 25.]\n",
      " [ 1.  0.  0.  0. 85. 14.]\n",
      " [ 0.  0.  0.  1. 80. 18.]]\n",
      "Dữ liệu huấn luyện đã chuẩn hóa:\n",
      " [[-0.70710678  0.         -0.70710678  1.41421356  0.32708852  0.11624764]\n",
      " [-0.70710678  0.          1.41421356 -0.70710678 -1.35508101  1.16247639]\n",
      " [ 1.41421356  0.         -0.70710678 -0.70710678  1.02799249 -1.27872403]]\n",
      "Dữ liệu kiểm tra đã chuẩn hóa:\n",
      " [[-0.70710678  1.         -0.70710678 -0.70710678 -0.37381545  2.55744805]]\n"
     ]
    }
   ],
   "source": [
    "#by using sklearn.feature_extraction import DictVectorizer, we can atract information that we needs! \n",
    "data = [\n",
    "    {'city': 'New York', 'temperature': 21, 'humidity': 68},\n",
    "    {'city': 'Los Angeles', 'temperature': 25, 'humidity': 75},\n",
    "    {'city': 'Chicago', 'temperature': 14, 'humidity': 85},\n",
    "    {'city': 'San Francisco', 'temperature': 18, 'humidity': 80}\n",
    "]\n",
    "\n",
    "# Bước 2: Khởi tạo DictVectorizer\n",
    "vec = DictVectorizer(sparse=False)\n",
    "\n",
    "# Bước 3: Chuyển đổi dữ liệu từ điển sang ma trận\n",
    "X = vec.fit_transform(data)\n",
    "\n",
    "# Bước 4: Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test = train_test_split(X, test_size=0.25, random_state=42)\n",
    "\n",
    "# Bước 5: Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# In ra các đặc tính đã được biến đổi và dữ liệu đã được chuẩn hóa\n",
    "print(\"Các đặc tính:\", vec.get_feature_names_out())\n",
    "print(\"Dữ liệu sau khi biến đổi:\\n\", X)\n",
    "print(\"Dữ liệu huấn luyện đã chuẩn hóa:\\n\", X_train_scaled)\n",
    "print(\"Dữ liệu kiểm tra đã chuẩn hóa:\\n\", X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.0013551 , 0.0026405 , 0.00199675]]), array([[ 0.00282631],\n",
      "       [-0.00587861],\n",
      "       [ 0.00450246]])]\n"
     ]
    }
   ],
   "source": [
    "#Neutral Network from scratch, we only make the sigmoid function, the other can be contruct as well, such as ReLU\n",
    "#We base on cross_entropy lost function, this will ensure maybe the best results we can have \n",
    "\n",
    "class Neutral_Network: \n",
    "    def __init__(self, expoch = 100, layers = [1,3,1]):  \n",
    "        self.expoch = expoch \n",
    "        self.layers = layers  \n",
    "        #first intialize! \n",
    "        self.W = [np.random.normal(loc = 0, scale = 0.01, size = (layers[x], layers[x+1])) for x in range(0,len(layers)-1)]\n",
    "        self.B = [np.random.normal(loc = 0, scale = 0.01, size = (1,layers[x])) for x in range(0,len(layers)-1)]\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))  \n",
    "    \n",
    "    def d_sigmoid(self,x):\n",
    "        #derivative of sigmoid function (this can be proof!) \n",
    "        return x * (1-x) \n",
    "\n",
    "    def fit(self,x,y): \n",
    "\n",
    "        #Forward Technique (as a child, we have to run Native using A[T] = X*W.T + b, for T is the Layer we are using)\n",
    "        #Note that, A[0] = X, A[len(layers) - 1] = Y!, W[layer] = W between layer and layer + 1, the same for B \n",
    "        A = [x] \n",
    "        \n",
    "        #we come for forward technique, that is running straight \n",
    "        for layer in range(0,len(self.layers) - 1): \n",
    "            A.append(self.sigmoid(np.dot(A[-1],self.W[layer]) + self.B[layer])) \n",
    "\n",
    "        #after ther forward, we will back_track to find the best result! \n",
    "        #Step 1: find dL/dA[-1] -> step 2: find dL/dw and dL / db, step 3: return to step 1\n",
    "\n",
    "        da = [(-y/A[-1]) + (1-y)/(1-A[-1])] #step 1 done!\n",
    "        dw = [] #this stand for dL / dw[T], for T is the layer ! \n",
    "        db = [] \n",
    "    \n",
    "        for layer in reversed(range(0,len(self.layers) - 1)): \n",
    "            #dL/dw = dL/dA[T] * dA[T]/dz[T] * dz... \n",
    "            dw.append(np.dot((A[layer-1]).T, self.d_sigmoid(A[layer]) * da[-1])) \n",
    "            db.append() \n",
    "            da.append()\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Neutral_Network()  \n",
    "A.fit([1,2],[3,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
